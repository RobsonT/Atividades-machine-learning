{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HHGEOHd2xquO"
   },
   "source": [
    "# **ATIVIDADE 1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oshAdjE0wr8N"
   },
   "outputs": [],
   "source": [
    "#Arquivo com os as funções solicitadas\n",
    "\n",
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#classe para as funções\n",
    "class funcoes():\n",
    "    def init(self):\n",
    "        pass\n",
    "\n",
    "    def RSS(self, y_predict, y_true):\n",
    "        RSS = np.sum((y_true - y_predict)**2)\n",
    "        return RSS\n",
    "\n",
    "    def R2(self, y_predict, y_true):\n",
    "        TSS = np.sum((y_true - np.mean(y_true))**2)\n",
    "        R2 = 1 - self.RSS(y_predict, y_true)/TSS\n",
    "        return R2\n",
    "      \n",
    "    def MSE(self, y_predict, y_true):\n",
    "        return np.mean((y_true - y_predict) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUGAoYt2pXFE"
   },
   "source": [
    "# **Regressões**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qb5NhDBl6Qt1"
   },
   "outputs": [],
   "source": [
    "#implementação dos métodos solicitados\n",
    "\n",
    "class RLA():\n",
    "  #Regressão Linear univariada-método analítico\n",
    "\n",
    "    def _init_(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        #tirando a media x = amostra, y = rotolos (ou observacao)\n",
    "        x_media = np.mean(x)\n",
    "        y_media = np.mean(y)\n",
    "\n",
    "        #calculando o valor de beta1\n",
    "        self.beta1 = np.sum((x - x_media)*(y - y_media)) / np.sum((x - x_media)**2)\n",
    "        #Calculo do Beta0\n",
    "        self.beta0 = y_media - self.beta1*x_media\n",
    "\n",
    "    def predict(self,x):\n",
    "\n",
    "        # Y e o valor predito calculado\n",
    "        self.Y = self.beta0 + self.beta1*x\n",
    "        return self.Y \n",
    "\n",
    "class RLGD():\n",
    "      #Regressão Linear univariada-gradiente descendente\n",
    "         \n",
    "    def __init__(self, learning_rate=0.01, epocas=100):\n",
    "      #Define uma reta mais próxima da reta real.\n",
    "      #inicializando os pontos de forma aleatória\n",
    "      #O learning_rate é a taxa de aprendizado, o quanto ele vai atualizar os valores de w(beta).\n",
    "      #As épocas é quantas vezes ele vai atualizar os pesos(valores de w).\n",
    "     \n",
    "        print(\"a\")\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta0 = random.random()\n",
    "        self.beta1 = random.random()\n",
    "        self.epocas = epocas\n",
    "\n",
    "    def calculo_gradiente_decrescente(self, x, y):\n",
    "\n",
    "        y_predicted = self.predict(x)\n",
    "        erro = y - y_predicted \n",
    "\n",
    "        self.beta0 = self.beta0 + (self.learning_rate * np.mean(erro))\n",
    "        self.beta1 = self.beta1 + (self.learning_rate * np.mean(erro * x))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        #treinando a RLGD\n",
    "        #List serve para converter uma variável para lista.\n",
    "        print(self.epocas)\n",
    "        for _ in list(range(self.epocas)):\n",
    "            self.calculo_gradiente_decrescente(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        #predição do RLGD\n",
    "\n",
    "        beta = self.beta0 + (self.beta1*x)\n",
    "        return beta\n",
    "\n",
    "class MLR():\n",
    "    #Regressão Linear Multivariada\n",
    "\n",
    "    def _init_(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        #treinando a MLR\n",
    "        #np.ones cria um vetor de 1's\n",
    "        #np.hstack concatena as matrizes\n",
    "\n",
    "        v_ones = np.ones((x.shape[0],1))\n",
    "        x = np.hstack((v_ones,x))\n",
    "\n",
    "        valor_aux = np.linalg.inv(np.matmul(x.T,x))\n",
    "        self.beta = np.matmul(np.matmul(valor_aux,x.T),y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_predict = np.array([])\n",
    "\n",
    "        #Laço para equação de calculo da MLR b0 + b1*x1 ... bn*xn\n",
    "        for i in x:\n",
    "            y_predict = np.append(y_predict, self.beta[0] + np.matmul(i, self.beta[1:].T))\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "class MLRGD():\n",
    "    #Regressão Linear Multivariada com gradiente decrescente\n",
    "\n",
    "    def _init_(self, learning_rate=0.01, epochs=1):\n",
    "      \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoca = epoca\n",
    "        self.beta = np.array([])\n",
    "\n",
    "    def calculate_gradient_descent(self,x, y):\n",
    "\n",
    "        y_predicted = self.predict(x)\n",
    "        erro = y - y_predicted\n",
    "\n",
    "        features_size = x.shape[1]\n",
    "\n",
    "        for i in range(features_size):\n",
    "            self.beta[i] += (self.learning_rate * np.mean(erro * x[:, i]))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        ones = np.ones((x.shape[0],1))\n",
    "        x = np.hstack((ones,x))\n",
    "\n",
    "        for _ in range(x.shape[1]):\n",
    "            self.b = np.append(self.b, random.random())\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.calculate_gradient_descent(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        y_predict = np.array([])\n",
    "\n",
    "        #Laço para equação de calculo da MLR b0 + b1*x1 ... bn*xn\n",
    "        for i in x:\n",
    "            y_predict = np.append(y_predict, b[0] + np.matmul(i, beta[1:].T))\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "class MLRGDE():\n",
    "    #Regressão Linear Multivariada com gradiente decrescente estocástico\n",
    "    # @ = np.matmul(multiplicação de matriz)\n",
    "    \n",
    "    def _init_(self, learning_rate=0.01, epochs=1):\n",
    "      \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoca = epoca\n",
    "        self.beta = np.array([])\n",
    "\n",
    "    def calculate_gradient_descent_estocastico(self,x, y):\n",
    "\n",
    "        y_predicted = self.predict(x)\n",
    "        erro = y - y_predicted\n",
    "\n",
    "        features_size = x.shape[1]\n",
    "    \n",
    "        for i in range(features_size):\n",
    "            self.beta[i] += (self.learning_rate * (erro @ (x[:, i])))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        ones = np.ones((x.shape[0],1))\n",
    "        x = np.hstack((ones,x))\n",
    "\n",
    "        for _ in range(x.shape[1]):\n",
    "            self.b = np.append(self.b, random.random())\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.calculate_gradient_descent(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        y_predict = np.array([])\n",
    "\n",
    "        #Laço para equação de calculo da MLR b0 + b1*x1 ... bn*xn\n",
    "        for i in x:\n",
    "            y_predict = np.append(y_predict, b[0] + np.matmul(i, beta[1:].T))\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "class RQ():\n",
    "    #Regressão quadrática usando regressão múltipla\n",
    "\n",
    "    def _init_(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        #treinando a MLR\n",
    "        #np.hstack concatena as matrizes\n",
    "\n",
    "        double_x = x*x\n",
    "        x = np.hstack((x, double_x))\n",
    "\n",
    "        self.model = MLR()\n",
    "        self.model.fit(x,y)\n",
    "        self.beta = self.model.beta\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        double_x = x*x\n",
    "        x = np.hstack((x, double_x))\n",
    "\n",
    "        predict = self.model.predict(x)\n",
    "\n",
    "        return predict\n",
    "\n",
    "class RC():\n",
    "      #Regressão cúbica usando regressão múltipla\n",
    "\n",
    "    def _init_(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        #treinando a MLR\n",
    "        #np.ones cria um vetor de 1's\n",
    "        #np.hstack concatena as matrizes\n",
    "\n",
    "        double_x = x*x\n",
    "        triple_x = x*double_x\n",
    "        x = np.hstack((x, double_x))\n",
    "        x = np.hstack((x, triple_x))\n",
    "\n",
    "        self.model = MLR()\n",
    "        self.model.fit(x,y)\n",
    "        self.beta = self.model.beta\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        double_x = x*x\n",
    "        triple_x = x*double_x\n",
    "        x = np.hstack((x, double_x))\n",
    "        x = np.hstack((x, triple_x)) \n",
    "\n",
    "        predict = self.model.predict(x)\n",
    "\n",
    "        return predict\n",
    "\n",
    "class RLMGD():\n",
    "\n",
    "    def _init_(self, learning_rate=0.01, epochs=1, lambida = 1):\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoca = epoca\n",
    "        self.beta = np.array([])\n",
    "        self.lambida = lambida\n",
    "\n",
    "    def calculo_regressao_linear_multivariada(self, x, y):\n",
    "        #freatures_size = numero de coulunas\n",
    "        y_predicted = self.predict(x)\n",
    "        erro = y - y_predicted\n",
    "        features_size = x.shape[1]\n",
    "        n = features_size\n",
    "        \n",
    "        for i in range(features_size):\n",
    "            self.beta[i] += (self.learning_rate * np.mean(erro * x[:, i]) - (lambida/n * self.beta[i]))\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        ones = np.ones((x.shape[0],1))\n",
    "        x = np.hstack((ones,x))\n",
    "       \n",
    "        for _ in range(x.shape[1]):\n",
    "            self.b = np.append(self.b, random.random())\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            self.calculate_gradient_descent(x, y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "\n",
    "        y_predict = np.array([])\n",
    "\n",
    "          #Laço para equação de calculo de MLR b0 + b1*x1 ... + bn*xn\n",
    "        for i in x:\n",
    "            y_predict = np.append(y_predict, b[0] + np.matmul(i, beta[1:].T))\n",
    "\n",
    "        return y_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VSd_APL9EGn"
   },
   "source": [
    "# **TESTES**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBiTYPEjBkvO"
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/housing.data\", delimiter=\",\")\n",
    "x = data[:, 12]\n",
    "y = data[:, 13]\n",
    "\n",
    "#para multivariada\n",
    "x_aux = data[:,1:2]\n",
    "\n",
    "np.random.shuffle(data) \n",
    "\n",
    "percentual = int(x.shape[0]*0.8) # 80% dos valores de amostra de x\n",
    "x_train\t= x[:percentual] #pegando 80% dos valores de amostra de x (FIT)\n",
    "y_train\t= y[:percentual] #pegando 80% dos valores de amostra de y (FIT)\n",
    "x_teste = x[percentual:] #pegando 20% dos valores de amostra de x (PREDICT)\n",
    "y_teste = y[percentual:] #pegando 20% dos valores de amostra de y (PREDICT)\n",
    "\n",
    "x_train_aux\t= x_aux[:percentual] #pegando 80% dos valores de amostra de x (FIT)\n",
    "x_teste_aux = x_aux[percentual:] #pegando 20% dos valores de amostra de x (PREDICT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PaxPhVzuOkgA"
   },
   "source": [
    "\n",
    "\n",
    "# Questão 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "0JAx8CmuOv13",
    "outputId": "0e09d761-9bbd-4901-d2c9-ba3df4214c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Coeficientes: b0= e b1=  (34.52757143789147, -0.9523979364761815)\n",
      "###########---Treino---###########\n",
      "R2:  0.5394023951894238\n",
      "MSE:  39.991132915445704\n",
      "###########---Teste---###########\n",
      "None\n",
      "R2:  0.5656938948393684\n",
      "MSE:  32.52639020388591\n",
      "Coeficientes: b0= e b1=  [ 2.08185542e+01  2.78097680e-01 -2.04705523e-03]\n",
      "###########---Treino---###########\n",
      "R2:  0.11164103479698206\n",
      "MSE:  77.13127702579389\n",
      "###########---Teste---###########\n",
      "None\n",
      "R2:  0.24698616850277366\n",
      "MSE:  56.39529682214139\n",
      "Coeficientes: b0= e b1=  [ 2.06068708e+01  6.84908516e-01 -1.78829378e-02  1.30624823e-04]\n",
      "###########---Treino---###########\n",
      "R2:  0.13907378758615163\n",
      "MSE:  74.74944340015135\n",
      "###########---Teste---###########\n",
      "None\n",
      "R2:  0.2713049185671762\n",
      "MSE:  54.57399810110919\n"
     ]
    }
   ],
   "source": [
    "f_RLA = RLA()\n",
    "f_RLGD = RLGD(epocas=1500, learning_rate=0.001)\n",
    "f_RQ = RQ()\n",
    "f_RC = RC()\n",
    "funcao = funcoes()\n",
    "\n",
    "f_RLA.fit(x_train, y_train)\n",
    "y_train_predict = f_RLA.predict(x_train)\n",
    "y_test_predict = f_RLA.predict(x_teste)\n",
    "\n",
    "print(\"Coeficientes: b0= e b1= \", (f_RLA.beta0, f_RLA.beta1))\n",
    "print(\"###########---Treino---###########\")\n",
    "print(\"R2: \", funcao.R2(y_train_predict,y_train ))\n",
    "print(\"MSE: \", funcao.MSE(y_train_predict, y_train))\n",
    "print(print(\"###########---Teste---###########\"))\n",
    "print(\"R2: \", funcao.R2(y_test_predict, y_teste))\n",
    "print(\"MSE: \", funcao.MSE(y_test_predict, y_teste))\n",
    "\n",
    "\n",
    "\n",
    "f_RQ.fit(x_train_aux, y_train)\n",
    "y_train_predict = f_RQ.predict(x_train_aux)\n",
    "y_test_predict = f_RQ.predict(x_teste_aux)\n",
    "\n",
    "print(\"Coeficientes: b0= e b1= \", (f_RQ.beta))\n",
    "print(\"###########---Treino---###########\")\n",
    "print(\"R2: \", funcao.R2(y_train_predict,y_train ))\n",
    "print(\"MSE: \", funcao.MSE(y_train_predict, y_train))\n",
    "print(print(\"###########---Teste---###########\"))\n",
    "print(\"R2: \", funcao.R2(y_test_predict, y_teste))\n",
    "print(\"MSE: \", funcao.MSE(y_test_predict, y_teste))\n",
    "\n",
    "f_RC.fit(x_train_aux, y_train)\n",
    "y_train_predict = f_RC.predict(x_train_aux)\n",
    "y_test_predict = f_RC.predict(x_teste_aux)\n",
    "\n",
    "print(\"Coeficientes: b0= e b1= \", (f_RC.beta))\n",
    "print(\"###########---Treino---###########\")\n",
    "\n",
    "print(\"R2: \", funcao.R2(y_train_predict,y_train ))\n",
    "print(\"MSE: \", funcao.MSE(y_train_predict, y_train))\n",
    "print(print(\"###########---Teste---###########\"))\n",
    "print(\"R2: \", funcao.R2(y_test_predict, y_teste))\n",
    "print(\"MSE: \", funcao.MSE(y_test_predict, y_teste))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "Coeficientes: b0= e b1=  (10.973986094307332, 0.4596242442790405)\n",
      "###########---Treino---###########\n",
      "R2:  -1.0279982444763505\n",
      "MSE:  176.07982868364675\n",
      "###########---Teste---###########\n",
      "None\n",
      "R2:  -1.120752556501209\n",
      "MSE:  158.82904789729804\n"
     ]
    }
   ],
   "source": [
    "f_RLGD.fit(x_train, y_train)\n",
    "y_train_predict = f_RLGD.predict(x_train)\n",
    "y_test_predict = f_RLGD.predict(x_teste)\n",
    "\n",
    "print(\"Coeficientes: b0= e b1= \", (f_RLGD.beta0, f_RLGD.beta1))\n",
    "print(\"###########---Treino---###########\")\n",
    "print(\"R2: \", funcao.R2(y_train_predict,y_train ))\n",
    "print(\"MSE: \", funcao.MSE(y_train_predict, y_train))\n",
    "print(print(\"###########---Teste---###########\"))\n",
    "print(\"R2: \", funcao.R2(y_test_predict, y_teste))\n",
    "print(\"MSE: \", funcao.MSE(y_test_predict, y_teste))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XF2LXFSVkL1"
   },
   "source": [
    "C)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "teste.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
